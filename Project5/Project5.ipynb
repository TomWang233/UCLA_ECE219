{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project5.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3TVXsTXKNeEg","colab_type":"code","colab":{}},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0GBfQHeYc_t","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NB0GqhaoPpc8","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=1CDKle_lotCdVvBH2maBEKs2xw2H_aniC'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('tweets_#nfl.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"55ieR2v1PpkI","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=16TFQYSbcxqmsCKGtM17ezv1r92zHqsOX'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('tweets_#patriots.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBvGfXciPpqU","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=1q46x9I4MyPJ2EMBvtz97JoOTQghc0Us5'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('tweets_#sb49.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sd19cjD_PpwL","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=1XEM8yOagqt0uQufcZb2Bx3FtuL1yiQIL'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('tweets_#superbowl.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_qjdZVcPm49","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=1P__NlS3CSm_Aw47zRL6kh6p4CG7Vdk8x'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('tweets_#gohawks.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdLYIPM1WVgZ","colab_type":"code","colab":{}},"source":["link = 'https://drive.google.com/open?id=1jK99nBFS9XFLaiiXTSlPl-tYt8iikmpb'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('tweets_#gopatriots.txt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZAtk1k9V-NP","colab_type":"code","colab":{}},"source":["txts = ['tweets_#nfl.txt', 'tweets_#patriots.txt','tweets_#sb49.txt', \n","        'tweets_#superbowl.txt', 'tweets_#gohawks.txt', 'tweets_#gopatriots.txt']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QgqTSYHxXY8c","colab_type":"text"},"source":["# Question 1"]},{"cell_type":"code","metadata":{"id":"mUuZhmUpThvG","colab_type":"code","outputId":"f3dba31e-1ae4-4de4-8936-c2cb63d7e3ce","executionInfo":{"status":"ok","timestamp":1584917254211,"user_tz":420,"elapsed":810022,"user":{"displayName":"ZICHENG HE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLTshIY5tG-AMuuZ1BoIhlJe0BPnghDKG20e2q=s64","userId":"04389277780657270813"}},"colab":{"base_uri":"https://localhost:8080/","height":433}},"source":["import numpy as np\n","import pandas as pd\n","import json\n","\n","def data_processing(txt):\n","    timestamp = []\n","    tweets = []\n","    followers = []\n","    retweets = []\n","    with open(txt, 'r') as current_txt:\n","        for line in current_txt:\n","            json_object = json.loads(line)\n","            tweets.append(1)\n","            timestamp.append(json_object['citation_date'])\n","            followers.append(json_object['author']['followers'])\n","            retweets.append(json_object['metrics']['citations']['total'])\n","        df = pd.DataFrame({'tweets' : tweets,'timestamp' : timestamp,\n","                           'followers' : followers,\n","                           'retweeted times' : retweets},\n","                          columns = ['tweets', 'timestamp', 'followers', 'retweeted times'])\n","        tweets_per_hour = ((sum(tweets))/((max(timestamp)-min(timestamp))/3600.0))\n","        print('Average number of tweets per hour is: ', tweets_per_hour)\n","        average_followers = sum(followers)/(sum(tweets))\n","        print('Average number of followers of users posting the tweets per tweet is: ', average_followers)\n","        average_retweets = sum(retweets)/(sum(tweets))\n","        print('Average number of retweets per tweet is:  ', average_retweets)\n","        \n","for txt in txts:\n","    print('Hashtag: ' + txt[7:-4])\n","    data_processing(txt)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Hashtag: #nfl\n","Average number of tweets per hour is:  397.0213901819841\n","Average number of followers of users posting the tweets per tweet is:  4662.37544523693\n","Average number of retweets per tweet is:   1.5344602655543254\n","Hashtag: #patriots\n","Average number of tweets per hour is:  750.89426460689\n","Average number of followers of users posting the tweets per tweet is:  3280.4635616550277\n","Average number of retweets per tweet is:   1.7852871288476946\n","Hashtag: #sb49\n","Average number of tweets per hour is:  1276.8570598680474\n","Average number of followers of users posting the tweets per tweet is:  10374.160292019487\n","Average number of retweets per tweet is:   2.52713444111402\n","Hashtag: #superbowl\n","Average number of tweets per hour is:  2072.11840170408\n","Average number of followers of users posting the tweets per tweet is:  8814.96799424623\n","Average number of retweets per tweet is:   2.3911895819207736\n","Hashtag: #gohawks\n","Average number of tweets per hour is:  292.48785062173687\n","Average number of followers of users posting the tweets per tweet is:  2217.9237355281984\n","Average number of retweets per tweet is:   2.0132093991319877\n","Hashtag: #gopatriots\n","Average number of tweets per hour is:  40.95469800606194\n","Average number of followers of users posting the tweets per tweet is:  1427.2526051635405\n","Average number of retweets per tweet is:   1.4081919101697078\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B8QHTtfkE4wf","colab_type":"text"},"source":["# Question 2"]},{"cell_type":"code","metadata":{"id":"ThUECKj-E7uL","colab_type":"code","outputId":"11adf156-7b05-48f7-a87f-819a75f309f8","executionInfo":{"status":"ok","timestamp":1584917327613,"user_tz":420,"elapsed":883418,"user":{"displayName":"ZICHENG HE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLTshIY5tG-AMuuZ1BoIhlJe0BPnghDKG20e2q=s64","userId":"04389277780657270813"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import matplotlib.pyplot as plt\n","\n","def histogram_helper(txt):\n","    timestamp = []\n","    with open(txt, 'r') as current_txt:\n","        for line in current_txt:\n","            json_object = json.loads(line)\n","            timestamp.append(json_object['citation_date'])\n","        histogram(timestamp, txt)\n","\n","def histogram(timestamp, txt):\n","    one_hour_bin = [0] * int((max(timestamp)-min(timestamp))/3600+1)\n","    start_time = min(timestamp)\n","    for time in timestamp:\n","        one_hour_bin[int((time-start_time)/3600)] += 1\n","    plt.figure(figsize=(20,10))\n","    plt.bar([i for i in range(0,len(one_hour_bin))], one_hour_bin, width = 1)\n","    plt.xlabel('Hour')\n","    plt.ylabel('Number of Tweets')\n","    plt.title('Hashtag: ' + txt[7:-4])\n","    plt.show()\n","\n","for txt in txts:\n","  if txt in ['tweets_#superbowl.txt','tweets_#nfl.txt']:\n","    histogram_helper(txt)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABJ4AAAJcCAYAAAC4425vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJI2FhSdJkiRJkiSNxf8BD4CVHe6oCOIAAAAASUVORK5CYII=\n","text/plain":["<Figure size 1440x720 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABKUAAAJcCAYAAAAo8BegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJ0ug+AQCRsNzAFKdzAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 1440x720 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"KJPUv-vsQNYi","colab_type":"text"},"source":["# Question 3"]},{"cell_type":"code","metadata":{"id":"SCBuRvQ5QPCD","colab_type":"code","outputId":"2dff5567-5fd3-4f18-81c8-fefb4c3a27b7","executionInfo":{"status":"ok","timestamp":1584917536883,"user_tz":420,"elapsed":1092680,"user":{"displayName":"ZICHENG HE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLTshIY5tG-AMuuZ1BoIhlJe0BPnghDKG20e2q=s64","userId":"04389277780657270813"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pytz\n","import datetime\n","from statsmodels.formula.api import ols\n","from statsmodels.regression.linear_model import RegressionResults\n","import numpy as np\n","import pandas as pd\n","import json\n","import csv\n","\n","processed_txts = ['p_tweets_#nfl.txt', 'p_tweets_#patriots.txt','p_tweets_#sb49.txt', \n","                  'p_tweets_#superbowl.txt', 'p_tweets_#gohawks.txt', 'p_tweets_#gopatriots.txt']\n","\n","for i in range(len(txts)):\n","    with open(txts[i], 'r') as reader:\n","        headers = ['timestamp_raw','tweets',\n","                   'retweets','followers','followers_max']\n","        with open(processed_txts[i], 'w') as writer:\n","            csv_writer = csv.writer(writer, lineterminator='\\n')\n","            csv_writer.writerow(headers)\n","            for line in reader:\n","                json_object = json.loads(line)\n","                response =  [json_object['citation_date'],1,\n","                             json_object['metrics']['citations']['total'],\n","                             json_object['author']['followers'], \n","                             json_object['author']['followers']]\n","                csv_writer.writerow(response)\n","\n","def convert_date(txt):\n","    pst_tz = pytz.timezone('America/Los_Angeles')\n","    utc_tz = pytz.UTC\n","    txt['date_pst'] = pd.to_datetime(txt['timestamp_raw'], unit='s').apply(lambda x: x.tz_localize(utc_tz).astimezone(pst_tz))\n","    txt['date'] = txt['date_pst'].apply(lambda x: x.strftime('%Y%m%d'))\n","    txt['hour'] = txt['date_pst'].apply(lambda x: x.hour)\n","    txt['minute'] = txt['date_pst'].apply(lambda x: x.minute)\n","\n","def ols_method(txt):\n","    training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour\", data=txt)\n","    result = training.fit()\n","    print(\"MSE is: \",result.mse_total)\n","    print(result.summary())\n","\n","p_nfl = pd.read_csv('p_tweets_#nfl.txt',delimiter=',')\n","p_patriots = pd.read_csv('p_tweets_#patriots.txt',delimiter=',')\n","p_sb49 = pd.read_csv('p_tweets_#sb49.txt',delimiter=',')\n","p_superbowl = pd.read_csv('p_tweets_#superbowl.txt',delimiter=',')\n","p_gohawks = pd.read_csv('p_tweets_#gohawks.txt',delimiter=',')\n","p_gopatriots = pd.read_csv('p_tweets_#gopatriots.txt',delimiter=',')\n","\n","convert_date(p_nfl)\n","nfl_processed = p_nfl.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max})\n","nfl_processed['next_tweets'] = nfl_processed['tweets']\n","nfl_processed.next_tweets = nfl_processed.next_tweets.shift(-1)\n","print('#nfl')\n","ols_method(nfl_processed)\n","\n","convert_date(p_patriots)\n","patriots_processed = p_patriots.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max})\n","patriots_processed['next_tweets'] = patriots_processed['tweets']\n","patriots_processed.next_tweets = patriots_processed.next_tweets.shift(-1)\n","print('#patriots')\n","ols_method(patriots_processed)\n","\n","convert_date(p_sb49)\n","sb49_processed = p_sb49.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max})\n","sb49_processed['next_tweets'] = sb49_processed['tweets']\n","sb49_processed.next_tweets = sb49_processed.next_tweets.shift(-1)\n","print('#sb49')\n","ols_method(sb49_processed)\n","\n","convert_date(p_superbowl)\n","superbowl_processed = p_superbowl.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max})\n","superbowl_processed['next_tweets'] = superbowl_processed['tweets']\n","superbowl_processed.next_tweets = superbowl_processed.next_tweets.shift(-1)\n","print('#superbowl')\n","ols_method(superbowl_processed)\n","\n","convert_date(p_gohawks)\n","gohawk_processed = p_gohawks.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max})\n","gohawk_processed['next_tweets'] = gohawk_processed['tweets']\n","gohawk_processed.next_tweets = gohawk_processed.next_tweets.shift(-1)\n","print('#gohawks')\n","ols_method(gohawk_processed)\n","\n","convert_date(p_gopatriots)\n","gopatriots_processed = p_gopatriots.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max})\n","gopatriots_processed['next_tweets'] = gopatriots_processed['tweets']\n","gopatriots_processed.next_tweets = gopatriots_processed.next_tweets.shift(-1)\n","print('#gopatriots')\n","ols_method(gopatriots_processed)\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["#nfl\n","MSE is:  633429.0070680364\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:            next_tweets   R-squared:                       0.570\n","Model:                            OLS   Adj. R-squared:                  0.567\n","Method:                 Least Squares   F-statistic:                     152.9\n","Date:                Sun, 22 Mar 2020   Prob (F-statistic):          3.57e-103\n","Time:                        22:51:13   Log-Likelihood:                -4467.0\n","No. Observations:                 582   AIC:                             8946.\n","Df Residuals:                     576   BIC:                             8972.\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","Intercept       126.3866     43.357      2.915      0.004      41.230     211.543\n","tweets            0.5652      0.135      4.173      0.000       0.299       0.831\n","retweets         -0.1650      0.064     -2.578      0.010      -0.291      -0.039\n","followers         0.0001   2.51e-05      4.573      0.000    6.54e-05       0.000\n","followers_max    -0.0001   3.32e-05     -3.527      0.000      -0.000   -5.19e-05\n","hour              0.2969      3.176      0.093      0.926      -5.941       6.535\n","==============================================================================\n","Omnibus:                      665.410   Durbin-Watson:                   2.373\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           343898.587\n","Skew:                           4.594   Prob(JB):                         0.00\n","Kurtosis:                     121.731   Cond. No.                     8.66e+06\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 8.66e+06. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","#patriots\n","MSE is:  15651769.681432862\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:            next_tweets   R-squared:                       0.668\n","Model:                            OLS   Adj. R-squared:                  0.666\n","Method:                 Least Squares   F-statistic:                     233.8\n","Date:                Sun, 22 Mar 2020   Prob (F-statistic):          1.91e-136\n","Time:                        22:51:24   Log-Likelihood:                -5361.4\n","No. Observations:                 586   AIC:                         1.073e+04\n","Df Residuals:                     580   BIC:                         1.076e+04\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","Intercept       180.1751    183.925      0.980      0.328    -181.066     541.416\n","tweets            0.9145      0.071     12.937      0.000       0.776       1.053\n","retweets         -0.0681      0.058     -1.178      0.239      -0.181       0.045\n","followers     -1.098e-05   2.63e-05     -0.417      0.677   -6.27e-05    4.07e-05\n","followers_max     0.0001   9.17e-05      1.340      0.181   -5.72e-05       0.000\n","hour             -5.8597     13.765     -0.426      0.670     -32.896      21.176\n","==============================================================================\n","Omnibus:                      887.682   Durbin-Watson:                   1.998\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           690539.222\n","Skew:                           7.937   Prob(JB):                         0.00\n","Kurtosis:                     170.420   Cond. No.                     1.60e+07\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.6e+07. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","#sb49\n","MSE is:  89969077.52259727\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:            next_tweets   R-squared:                       0.804\n","Model:                            OLS   Adj. R-squared:                  0.802\n","Method:                 Least Squares   F-statistic:                     435.6\n","Date:                Sun, 22 Mar 2020   Prob (F-statistic):          4.54e-185\n","Time:                        22:51:42   Log-Likelihood:                -5231.3\n","No. Observations:                 536   AIC:                         1.047e+04\n","Df Residuals:                     530   BIC:                         1.050e+04\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","Intercept       235.0748    365.931      0.642      0.521    -483.778     953.928\n","tweets            1.1361      0.091     12.485      0.000       0.957       1.315\n","retweets         -0.1602      0.082     -1.953      0.051      -0.321       0.001\n","followers      9.695e-06    1.3e-05      0.743      0.458   -1.59e-05    3.53e-05\n","followers_max  9.418e-05   4.58e-05      2.056      0.040    4.17e-06       0.000\n","hour            -17.9297     26.914     -0.666      0.506     -70.801      34.941\n","==============================================================================\n","Omnibus:                     1070.760   Durbin-Watson:                   1.674\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1720654.660\n","Skew:                          13.993   Prob(JB):                         0.00\n","Kurtosis:                     279.154   Cond. No.                     1.67e+08\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.67e+08. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","#superbowl\n","MSE is:  262656185.05200258\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:            next_tweets   R-squared:                       0.800\n","Model:                            OLS   Adj. R-squared:                  0.798\n","Method:                 Least Squares   F-statistic:                     463.5\n","Date:                Sun, 22 Mar 2020   Prob (F-statistic):          6.72e-200\n","Time:                        22:52:12   Log-Likelihood:                -6039.9\n","No. Observations:                 586   AIC:                         1.209e+04\n","Df Residuals:                     580   BIC:                         1.212e+04\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","Intercept      -149.5572    605.382     -0.247      0.805   -1338.565    1039.451\n","tweets            2.2766      0.080     28.537      0.000       2.120       2.433\n","retweets         -0.2543      0.046     -5.544      0.000      -0.344      -0.164\n","followers        -0.0001    2.2e-05     -6.265      0.000      -0.000   -9.47e-05\n","followers_max     0.0007      0.000      4.889      0.000       0.000       0.001\n","hour            -20.4965     43.624     -0.470      0.639    -106.177      65.184\n","==============================================================================\n","Omnibus:                      973.862   Durbin-Watson:                   2.283\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1787388.254\n","Skew:                           9.272   Prob(JB):                         0.00\n","Kurtosis:                     272.925   Cond. No.                     2.21e+08\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 2.21e+08. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","#gohawks\n","MSE is:  1473073.132045348\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:            next_tweets   R-squared:                       0.476\n","Model:                            OLS   Adj. R-squared:                  0.471\n","Method:                 Least Squares   F-statistic:                     102.3\n","Date:                Sun, 22 Mar 2020   Prob (F-statistic):           1.10e-76\n","Time:                        22:52:16   Log-Likelihood:                -4663.7\n","No. Observations:                 569   AIC:                             9339.\n","Df Residuals:                     563   BIC:                             9365.\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","Intercept        99.5134     72.677      1.369      0.171     -43.237     242.264\n","tweets            1.2823      0.165      7.767      0.000       0.958       1.607\n","retweets         -0.1364      0.044     -3.113      0.002      -0.222      -0.050\n","followers        -0.0002   8.06e-05     -2.407      0.016      -0.000   -3.57e-05\n","followers_max  6.047e-05      0.000      0.403      0.687      -0.000       0.000\n","hour              1.3865      5.451      0.254      0.799      -9.321      12.094\n","==============================================================================\n","Omnibus:                      899.580   Durbin-Watson:                   2.216\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           747068.220\n","Skew:                           8.625   Prob(JB):                         0.00\n","Kurtosis:                     179.673   Cond. No.                     5.24e+06\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 5.24e+06. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","#gopatriots\n","MSE is:  96673.38736798511\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:            next_tweets   R-squared:                       0.627\n","Model:                            OLS   Adj. R-squared:                  0.623\n","Method:                 Least Squares   F-statistic:                     146.0\n","Date:                Sun, 22 Mar 2020   Prob (F-statistic):           1.33e-90\n","Time:                        22:52:16   Log-Likelihood:                -2932.2\n","No. Observations:                 440   AIC:                             5876.\n","Df Residuals:                     434   BIC:                             5901.\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","Intercept        13.0136     18.908      0.688      0.492     -24.149      50.176\n","tweets            0.3052      0.326      0.937      0.349      -0.335       0.945\n","retweets          0.4877      0.219      2.223      0.027       0.056       0.919\n","followers        -0.0001      0.000     -0.424      0.672      -0.001       0.000\n","followers_max -2.827e-05      0.000     -0.113      0.910      -0.001       0.000\n","hour             -0.3371      1.413     -0.239      0.812      -3.114       2.440\n","==============================================================================\n","Omnibus:                      346.712   Durbin-Watson:                   1.909\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           128856.413\n","Skew:                           2.206   Prob(JB):                         0.00\n","Kurtosis:                      86.720   Cond. No.                     9.12e+05\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 9.12e+05. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZhnKDIRyzbUM","colab_type":"text"},"source":["# Question 4"]},{"cell_type":"code","metadata":{"id":"Y_nt8wkWzdyG","colab_type":"code","outputId":"85ba3041-69cd-4f9a-b4d5-774cbdbfa973","executionInfo":{"status":"error","timestamp":1584918709963,"user_tz":420,"elapsed":46505,"user":{"displayName":"ZICHENG HE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLTshIY5tG-AMuuZ1BoIhlJe0BPnghDKG20e2q=s64","userId":"04389277780657270813"}},"colab":{"base_uri":"https://localhost:8080/","height":381}},"source":["import pytz\n","import datetime\n","from statsmodels.formula.api import ols\n","from statsmodels.regression.linear_model import RegressionResults\n","import numpy as np\n","import pandas as pd\n","import json\n","import csv\n","\n","\n","processed_txts = ['p_tweets_#nfl.txt', 'p_tweets_#patriots.txt','p_tweets_#sb49.txt', \n","                  'p_tweets_#superbowl.txt', 'p_tweets_#gohawks.txt', 'p_tweets_#gopatriots.txt']\n","\n","for i in range(len(txts)):\n","    with open(txts[i], 'r') as reader:\n","        headers = ['timestamp_raw','tweets',\n","                   'retweets','followers','followers_max','mentions','urls']\n","        with open(processed_txts[i], 'w') as writer:\n","            csv_writer = csv.writer(writer, lineterminator='\\n')\n","            csv_writer.writerow(headers)\n","            for line in reader:\n","                json_object = json.loads(line)\n","                response =  [json_object['citation_date'],1,\n","                             json_object['metrics']['citations']['total'],\n","                             json_object['author']['followers'], \n","                             json_object['author']['followers'],\n","                             len(json_object['tweet']['entities']['urls']),\n","                             len(json_object['tweet']['entities']['user_mentions'])]\n","                csv_writer.writerow(response)\n","\n","def convert_date(txt):\n","    pst_tz = pytz.timezone('America/Los_Angeles')\n","    utc_tz = pytz.UTC\n","    txt['date_pst'] = pd.to_datetime(txt['timestamp_raw'], unit='s').apply(lambda x: x.tz_localize(utc_tz).astimezone(pst_tz))\n","    txt['date'] = txt['date_pst'].apply(lambda x: x.strftime('%Y%m%d'))\n","    txt['hour'] = txt['date_pst'].apply(lambda x: x.hour)\n","    txt['minute'] = txt['date_pst'].apply(lambda x: x.minute)\n","\n","def ols_method(txt):\n","    training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=txt)\n","    result = training.fit()\n","    print(\"MSE is: \",result.mse_total)\n","    print(result.summary())\n","\n","p_nfl = pd.read_csv('p_tweets_#nfl.txt',delimiter=',')\n","p_patriots = pd.read_csv('p_tweets_#patriots.txt',delimiter=',')\n","p_sb49 = pd.read_csv('p_tweets_#sb49.txt',delimiter=',')\n","p_superbowl = pd.read_csv('p_tweets_#superbowl.txt',delimiter=',')\n","p_gohawks = pd.read_csv('p_tweets_#gohawks.txt',delimiter=',')\n","p_gopatriots = pd.read_csv('p_tweets_#gopatriots.txt',delimiter=',')\n","\n","convert_date(p_nfl)\n","nfl_processed = p_nfl.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max, 'mentions':np.sum,'urls':np.sum})\n","nfl_processed['next_tweets'] = nfl_processed['tweets']\n","nfl_processed.next_tweets = nfl_processed.next_tweets.shift(-1)\n","print('#nfl')\n","ols_method(nfl_processed)\n","\n","convert_date(p_patriots)\n","patriots_processed = p_patriots.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max, 'mentions':np.sum,'urls':np.sum})\n","patriots_processed['next_tweets'] = patriots_processed['tweets']\n","patriots_processed.next_tweets = patriots_processed.next_tweets.shift(-1)\n","print('#patriots')\n","ols_method(patriots_processed)\n","\n","convert_date(p_sb49)\n","sb49_processed = p_sb49.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max, 'mentions':np.sum,'urls':np.sum})\n","sb49_processed['next_tweets'] = sb49_processed['tweets']\n","sb49_processed.next_tweets = sb49_processed.next_tweets.shift(-1)\n","print('#sb49')\n","ols_method(sb49_processed)\n","\n","convert_date(p_superbowl)\n","superbowl_processed = p_superbowl.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max, 'mentions':np.sum,'urls':np.sum})\n","superbowl_processed['next_tweets'] = superbowl_processed['tweets']\n","superbowl_processed.next_tweets = superbowl_processed.next_tweets.shift(-1)\n","print('#superbowl')\n","ols_method(superbowl_processed)\n","\n","convert_date(p_gohawks)\n","gohawk_processed = p_gohawks.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max, 'mentions':np.sum,'urls':np.sum})\n","gohawk_processed['next_tweets'] = gohawk_processed['tweets']\n","gohawk_processed.next_tweets = gohawk_processed.next_tweets.shift(-1)\n","print('#gohawks')\n","ols_method(gohawk_processed)\n","\n","convert_date(p_gopatriots)\n","gopatriots_processed = p_gopatriots.groupby(pd.Grouper(key='date_pst',freq='60Min')).agg({'tweets':np.sum,'retweets':np.sum,\n","                                                                              'followers':np.sum,'followers_max':np.max,\n","                                                                              'hour':np.max, 'mentions':np.sum,'urls':np.sum})\n","gopatriots_processed['next_tweets'] = gopatriots_processed['tweets']\n","gopatriots_processed.next_tweets = gopatriots_processed.next_tweets.shift(-1)\n","print('#gopatriots')\n","ols_method(gopatriots_processed)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-0c8ea278e46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcsv_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 response =  [json_object['citation_date'],1,\n\u001b[1;32m     25\u001b[0m                              \u001b[0mjson_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'citations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"QWmAJhT4A837","colab_type":"text"},"source":["# Question 5"]},{"cell_type":"markdown","metadata":{"id":"wF_oJn3bmpka","colab_type":"text"},"source":["# #nfl"]},{"cell_type":"code","metadata":{"id":"nH80qacvA_lw","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=nfl_processed)\n","nfl_model = training.fit()\n","nfl_predict = nfl_model.predict(nfl_processed)\n","\n","\n","plt.plot(list(nfl_predict), list(nfl_processed['mentions']), 'o')\n","plt.title('#nfl number of mentions per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of mentions per tweet')\n","plt.show()\n","\n","plt.plot(list(nfl_predict), list(nfl_processed['urls']), 'o')\n","plt.title('#nfl number of urls per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of urls per tweet')\n","plt.show()\n","\n","plt.plot(list(nfl_predict), list(nfl_processed['retweets']), 'o')\n","plt.title('#nfl number of retweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of retweets')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N4alMNVSoQP1","colab_type":"text"},"source":["# #patriots"]},{"cell_type":"code","metadata":{"id":"p5BBOU2SoTFY","colab_type":"code","colab":{}},"source":["training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=patriots_processed)\n","patriots_model = training.fit()\n","patriots_predict = patriots_model.predict(patriots_processed)\n","\n","\n","plt.plot(list(patriots_predict), list(patriots_processed['tweets']), 'o')\n","plt.title('#patriots number of tweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of tweets')\n","plt.show()\n","\n","plt.plot(list(patriots_predict), list(patriots_processed['followers']), 'o')\n","plt.title('#patriots number of followers')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of followers')\n","plt.show()\n","\n","plt.plot(list(patriots_predict), list(patriots_processed['followers_max']), 'o')\n","plt.title('#patriots maximum number of followers')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('maximum number of followers')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sWWEXFHLo5ys","colab_type":"text"},"source":["# #sb49"]},{"cell_type":"code","metadata":{"id":"QVRzkg3Vo5KS","colab_type":"code","colab":{}},"source":["training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=sb49_processed)\n","sb49_model = training.fit()\n","sb49_predict = sb49_model.predict(sb49_processed)\n","\n","\n","plt.plot(list(sb49_predict), list(sb49_processed['tweets']), 'o')\n","plt.title('#sb49 number of tweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of tweets')\n","plt.show()\n","\n","plt.plot(list(sb49_predict), list(sb49_processed['followers']), 'o')\n","plt.title('#sb49 number of followers')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of followers')\n","plt.show()\n","\n","plt.plot(list(sb49_predict), list(sb49_processed['mentions']), 'o')\n","plt.title('#sb49 number of mentions per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of mentions per tweet')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qIUcxJemppJo","colab_type":"text"},"source":["# #superbowl"]},{"cell_type":"code","metadata":{"id":"LmXjl00rpsAM","colab_type":"code","colab":{}},"source":["training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=superbowl_processed)\n","superbowl_model = training.fit()\n","superbowl_predict = superbowl_model.predict(superbowl_processed)\n","\n","\n","plt.plot(list(superbowl_predict), list(superbowl_processed['retweets']), 'o')\n","plt.title('#superbowl number of retweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of retweets')\n","plt.show()\n","\n","plt.plot(list(superbowl_predict), list(superbowl_processed['urls']), 'o')\n","plt.title('#superbowl number of urls per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of urls per tweet')\n","plt.show()\n","\n","plt.plot(list(superbowl_predict), list(superbowl_processed['tweets']), 'o')\n","plt.title('#superbowl number of tweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of tweets')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AWD7pvMoqPpR","colab_type":"text"},"source":["# #gohawks"]},{"cell_type":"code","metadata":{"id":"xr2Drp4YqR-p","colab_type":"code","colab":{}},"source":["training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=gohawk_processed)\n","gohawks_model = training.fit()\n","gohawks_predict = gohawks_model.predict(gohawk_processed)\n","\n","\n","plt.plot(list(gohawks_predict), list(gohawk_processed['tweets']), 'o')\n","plt.title('#gohawks number of tweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of tweets')\n","plt.show()\n","\n","plt.plot(list(gohawks_predict), list(gohawk_processed['followers']), 'o')\n","plt.title('#gohawks number of followers')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of followers')\n","plt.show()\n","\n","plt.plot(list(gohawks_predict), list(gohawk_processed['mentions']), 'o')\n","plt.title('#gohawks number of mentions per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of mentions per tweet')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hw8Dh1mbqv07","colab_type":"text"},"source":["# #gopatriots"]},{"cell_type":"code","metadata":{"id":"CZoVhVfkqyin","colab_type":"code","colab":{}},"source":["training = ols(\"next_tweets ~ tweets + retweets + followers + followers_max + hour + mentions + urls\", data=gopatriots_processed)\n","gopatriots_model = training.fit()\n","gopatriots_predict = gopatriots_model.predict(gopatriots_processed)\n","\n","\n","plt.plot(list(gopatriots_predict), list(gopatriots_processed['retweets']), 'o')\n","plt.title('#gopatriots number of retweets')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of retweets')\n","plt.show()\n","\n","plt.plot(list(gopatriots_predict), list(gopatriots_processed['mentions']), 'o')\n","plt.title('#gopatriots number of mentions per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of mentions per tweet')\n","plt.show()\n","\n","plt.plot(list(gopatriots_predict), list(gopatriots_processed['urls']), 'o')\n","plt.title('#gopatriots number of urls per tweet')\n","plt.xlabel('Predicted Number of Tweets for Next Hour')\n","plt.ylabel('number of urls per tweet')\n","plt.show()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9Ubs8zbZj5z","colab_type":"text"},"source":["# Question 6"]},{"cell_type":"code","metadata":{"id":"FlmIgW63ZkRK","colab_type":"code","colab":{}},"source":["import datetime,time\n","import pytz\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","from statistics import mean\n","from sklearn.model_selection import KFold\n","import statsmodels.api as sm\n","from statsmodels.api import tools\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.datasets import make_regression\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.preprocessing import StandardScaler  \n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.model_selection import train_test_split\n","topics = [\"nfl\", \"patriots\", \"sb49\", \"superbowl\", \"gohawks\", \"gopatriots\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGyR5uXZkeLO","colab_type":"code","colab":{}},"source":["def transfer_time(data_raw,time_type):\n","    \n","    pst_tz = pytz.timezone('America/Los_Angeles')\n","    \n","    pddata_raw = pd.DataFrame(data_raw,columns=['time','tweets','retweets','followers','mentioned','media','active','author','favourites_count','title'])\n","    pddata_raw = pddata_raw.sort_values(by = 'time')\n","    pddata_raw = pddata_raw.reset_index(drop=True)               \n","    if time_type == 'hour':\n","        hour_accu = []\n","        for index, row in pddata_raw.iterrows():  \n","            p = datetime.datetime.fromtimestamp(row['time'], pst_tz)  \n","            hour_accu.append(((p.month-1)*31+p.day-14)*24+p.hour)                             \n","        pddata_raw['time'] = hour_accu\n","    elif time_type == 'minute':\n","        minu_accu = []\n","        for index, row in pddata_raw.iterrows():  \n","            p = datetime.datetime.fromtimestamp(row['time'], pst_tz)                    \n","            minu_accu.append((((p.month-1)*31+p.day-14)*24 + (p.hour-0))*12 + p.minute//5)             \n","        pddata_raw['time'] = minu_accu    \n","    else:\n","        print(\"Invalid time type\")\n","        \n","    return pddata_raw\n","\n","def generate_df(pddata_raw):\n","\n","    df = pd.DataFrame([],columns=['time unit','tweets','retweets','followers sum','followers max','mentioned','media','active','author','favourites_count','title'])\n","    \n","    col = pddata_raw.columns.get_loc('time')\n","    df['time unit'] = range(int(pddata_raw.iloc[len(pddata_raw.index)-1,col] - pddata_raw.iloc[0,col]+1))\n","\n","    df['tweets'] = pddata_raw.groupby(\"time\")['tweets'].sum()\n","    df['retweets'] = pddata_raw.groupby(\"time\")['retweets'].sum()\n","    df['followers sum'] = pddata_raw.groupby(\"time\")['followers'].sum()\n","    df['followers max'] = pddata_raw.groupby(\"time\")[\"followers\"].max()\n","    df['mentioned'] = pddata_raw.groupby(\"time\")['mentioned'].sum()\n","    df['media'] = pddata_raw.groupby(\"time\")['media'].sum()\n","    df['active'] = pddata_raw.groupby(\"time\")['active'].mean()  \n","    df['author'] = pddata_raw.groupby(\"time\")['author'].nunique() # count number of not-repeating authors    \n","    df['favourites_count'] = pddata_raw.groupby(\"time\")['favourites_count'].sum()\n","    df['title'] = pddata_raw.groupby(\"time\")['title'].mean()\n","    df = df.fillna(0).reset_index(drop=True)\n","    \n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fawh5ddnkeZF","colab_type":"code","colab":{}},"source":["def parse_dataset(txt):\n","    start_time = time.mktime(time.strptime(\"2015-02-01 08:00:00\",'%Y-%m-%d %H:%M:%S'))\n","    end_time = time.mktime(time.strptime(\"2015-02-01 20:00:00\",'%Y-%m-%d %H:%M:%S'))   \n","\n","    start_hour_idx = ((2-1)*31+1-14)*24+8\n","    end_hour_idx = ((2-1)*31+1-14)*24+20\n","    start_minute_idx = (((2-1)*31+1-14)*24 + (8-0))*12 + 0//5    \n","\n","    data_raw = [[],[],[]]\n","    with open(txt, 'r') as current_txt:\n","        for line in current_txt:\n","          row_tmp = []\n","          a = json.loads(line)\n","          citation_date = a['citation_date']\n","          tweet = 1\n","          retweet = a['metrics']['citations']['total']\n","          foll = a['author']['followers']             \n","          ment = len(a['tweet']['entities']['user_mentions'])        \n","          medi = len(a['tweet']['extended_entities']['media']) if 'extended_entities' in a['tweet'] else 0\n","          hist_tw = a['tweet']['user'][\"statuses_count\"]\n","          hist_yr = a['tweet']['user']['created_at'][-4:]\n","          acti = hist_tw/(2015-float(hist_yr)+1) \n","          auth = a['author']['name']\n","          favo = a['tweet']['user']['favourites_count']\n","          titl = len(a['title'])\n","        \n","          row_tmp.append(citation_date)        \n","          row_tmp.append(tweet)        \n","          row_tmp.append(retweet)\n","          row_tmp.append(foll)    \n","          row_tmp.append(ment) \n","          row_tmp.append(medi) \n","          row_tmp.append(acti)  \n","          row_tmp.append(auth)\n","          row_tmp.append(favo)\n","          row_tmp.append(titl)\n","        \n","          if citation_date < start_time:\n","              data_raw[0].append(row_tmp)\n","          elif citation_date < end_time:\n","              data_raw[1].append(row_tmp)\n","          else:\n","              data_raw[2].append(row_tmp)            \n","\n","    pddata_raw_1 = transfer_time(data_raw[0],'hour')\n","    pddata_raw_2 = transfer_time(data_raw[1],'minute')\n","    pddata_raw_2['time'] = pddata_raw_2['time'] - start_minute_idx\n","    pddata_raw_3 = transfer_time(data_raw[2],'hour')\n","    pddata_raw_3['time'] = pddata_raw_3['time'] - end_hour_idx - 1    \n","            \n","    df_1 = generate_df(pddata_raw_1)  \n","    df_y_1 = df_1.iloc[1:,1].reset_index(drop=True)\n","    df_1 = df_1[:len(df_y_1)]\n","    \n","    df_2 = generate_df(pddata_raw_2)\n","    df_y_2 = df_2.iloc[1:,1].reset_index(drop=True)\n","    df_2 = df_2[:len(df_y_2)]\n","   \n","    df_3 = generate_df(pddata_raw_3)\n","    df_y_3 = df_3.iloc[1:,1].reset_index(drop=True)\n","    df_3 = df_3[:len(df_y_3)]\n","    \n","    return (df_1.iloc[:,1:],df_y_1), (df_2.iloc[:,1:],df_y_2), (df_3.iloc[:,1:],df_y_3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TD92G2hJkkno","colab_type":"code","colab":{}},"source":["def train_lr(txt):  \n","    (df_1,df_y_1),(df_2,df_y_2),(df_3,df_y_3) = parse_dataset(txt)\n","    print('Parse data finished','\\n')\n","\n","    reg_1 = LinearRegression().fit(df_1, df_y_1)\n","    pred_y_1 = reg_1.predict(df_1)\n","    MSE_1 = mean_squared_error(df_y_1, pred_y_1)\n","    R2_1 = r2_score(df_y_1, pred_y_1)    \n","    print(topics[i], ' of time period 1')\n","    print('MSE for test data = ',MSE_1)\n","    print('R2 score for test data = ',R2_1,'\\n')   \n","\n","    reg_2 = LinearRegression().fit(df_2, df_y_2)\n","    pred_y_2 = reg_2.predict(df_2)\n","    MSE_2 = mean_squared_error(df_y_2, pred_y_2)\n","    R2_2 = r2_score(df_y_2, pred_y_2)    \n","    print(topics[i], ' of time period 2')\n","    print('MSE for test data = ',MSE_2)\n","    print('R2 score for test data = ',R2_2,'\\n') \n","\n","    reg_3 = LinearRegression().fit(df_3, df_y_3)\n","    pred_y_3 = reg_3.predict(df_3)\n","    MSE_3 = mean_squared_error(df_y_3, pred_y_3)\n","    R2_3 = r2_score(df_y_3, pred_y_3)    \n","    print(topics[i], ' of time period 3')\n","    print('MSE for test data = ',MSE_3)\n","    print('R2 score for test data = ',R2_3,'\\n') \n","    \n","    return (df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TxXA40yklHp","colab_type":"code","colab":{}},"source":["for txt in txts:\n","    print(txt[7:-4])\n","    (df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr(txt)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rl_KcbEsdLqQ","colab_type":"text"},"source":["# Question 7"]},{"cell_type":"code","metadata":{"id":"WsBsRhGxoTJx","colab_type":"code","colab":{}},"source":["def parse_dataset_2(files):\n","    start_time = time.mktime(time.strptime(\"2015-02-01 08:00:00\",'%Y-%m-%d %H:%M:%S'))\n","    end_time = time.mktime(time.strptime(\"2015-02-01 20:00:00\",'%Y-%m-%d %H:%M:%S'))   \n","\n","    start_hour_idx = ((2-1)*31+1-14)*24+8\n","    end_hour_idx = ((2-1)*31+1-14)*24+20\n","    start_minute_idx = (((2-1)*31+1-14)*24 + (8-0))*12 + 0//5    \n","        \n","    data_raw = [[],[],[]]\n","    for txt in txts:\n","        with open(txt, 'r') as current_txt:\n","          for line in current_txt:\n","            row_tmp = []\n","            a = json.loads(line)\n","            citation_date = a['citation_date']\n","            tweet = 1\n","            retweet = a['metrics']['citations']['total']\n","            foll = a['author']['followers']             \n","            ment = len(a['tweet']['entities']['user_mentions'])        \n","            medi = len(a['tweet']['extended_entities']['media']) if 'extended_entities' in a['tweet'] else 0\n","            hist_tw = a['tweet']['user'][\"statuses_count\"]\n","            hist_yr = a['tweet']['user']['created_at'][-4:]\n","            acti = hist_tw/(2015-float(hist_yr)+1) \n","            auth = a['author']['name']\n","            favo = a['tweet']['user']['favourites_count']\n","            titl = len(a['title'])\n","\n","            row_tmp.append(citation_date)        \n","            row_tmp.append(tweet)        \n","            row_tmp.append(retweet)\n","            row_tmp.append(foll)    \n","            row_tmp.append(ment) \n","            row_tmp.append(medi) \n","            row_tmp.append(acti)  \n","            row_tmp.append(auth)\n","            row_tmp.append(favo)\n","            row_tmp.append(titl)\n","\n","            # assign to 3 periods\n","            if citation_date < start_time:\n","                data_raw[0].append(row_tmp)\n","            elif citation_date < end_time:\n","                data_raw[1].append(row_tmp)\n","            else:\n","                data_raw[2].append(row_tmp)            \n","\n","    pddata_raw_1 = transfer_time(data_raw[0],'hour')\n","    pddata_raw_2 = transfer_time(data_raw[1],'minute')\n","    pddata_raw_2['time'] = pddata_raw_2['time'] - start_minute_idx\n","    pddata_raw_3 = transfer_time(data_raw[2],'hour')\n","    pddata_raw_3['time'] = pddata_raw_3['time'] - end_hour_idx - 1    \n","            \n","    df_1 = generate_df(pddata_raw_1)  \n","    df_y_1 = df_1.iloc[1:,1].reset_index(drop=True)\n","    df_1 = df_1[:len(df_y_1)]\n","    \n","    df_2 = generate_df(pddata_raw_2)\n","    df_y_2 = df_2.iloc[1:,1].reset_index(drop=True)\n","    df_2 = df_2[:len(df_y_2)]\n","   \n","    df_3 = generate_df(pddata_raw_3)\n","    df_y_3 = df_3.iloc[1:,1].reset_index(drop=True)\n","    df_3 = df_3[:len(df_y_3)]\n","    \n","    return (df_1.iloc[:,1:],df_y_1), (df_2.iloc[:,1:],df_y_2), (df_3.iloc[:,1:],df_y_3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuvCeZ0pdOsH","colab_type":"code","colab":{}},"source":["def train_lr_2(files):\n","    (df_1,df_y_1),(df_2,df_y_2),(df_3,df_y_3) = parse_dataset_2(files)\n","    print('Parse data finished','\\n')\n","\n","    reg_1 = LinearRegression().fit(df_1, df_y_1)\n","    pred_y_1 = reg_1.predict(df_1)\n","    MSE_1 = mean_squared_error(df_y_1, pred_y_1)\n","    R2_1 = r2_score(df_y_1, pred_y_1)    \n","    print('Time period 1')\n","    print('MSE for test data = ',MSE_1)\n","    print('R2 score for test data = ',R2_1,'\\n')   \n","\n","    reg_2 = LinearRegression().fit(df_2, df_y_2)\n","    pred_y_2 = reg_2.predict(df_2)\n","    MSE_2 = mean_squared_error(df_y_2, pred_y_2)\n","    R2_2 = r2_score(df_y_2, pred_y_2)    \n","    print('Time period 2')\n","    print('MSE for test data = ',MSE_2)\n","    print('R2 score for test data = ',R2_2,'\\n') \n","\n","    reg_3 = LinearRegression().fit(df_3, df_y_3)\n","    pred_y_3 = reg_3.predict(df_3)\n","    MSE_3 = mean_squared_error(df_y_3, pred_y_3)\n","    R2_3 = r2_score(df_y_3, pred_y_3)    \n","    print('Time period 3')\n","    print('MSE for test data = ',MSE_3)\n","    print('R2 score for test data = ',R2_3,'\\n') \n","    \n","    return (df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M-MJ0IngdOkM","colab_type":"code","colab":{}},"source":["(df_1, df_y_1, pred_y_1), (df_2, df_y_2, pred_y_2), (df_3, df_y_3, pred_y_3) = train_lr_2(txts)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_V3YVP6h3kN","colab_type":"text"},"source":["# Question 8"]},{"cell_type":"code","metadata":{"id":"me1HFkRBiBVS","colab_type":"code","colab":{}},"source":["def parse_dataset_ten_features(file):\n","    pst_tz = pytz.timezone('America/Los_Angeles')\n","    data_raw = []\n","    with open(txt, 'r') as current_txt:\n","          for line in current_txt:\n","            row_tmp = []\n","            a = json.loads(line)\n","            citation_date = a['citation_date']\n","            retweet = a['metrics']['citations']['total']\n","            foll = a['author']['followers']             \n","            ment = len(a['tweet']['entities']['user_mentions'])        \n","            medi = len(a['tweet']['extended_entities']['media']) if 'extended_entities' in a['tweet'] else 0\n","            hist_tw = a['tweet']['user'][\"statuses_count\"]\n","            hist_yr = a['tweet']['user']['created_at'][-4:]\n","            acti = hist_tw/(2015-float(hist_yr)+1) \n","            auth = a['author']['name']\n","            favo = a['tweet']['user']['favourites_count']\n","            titl = len(a['title'])\n","\n","            row_tmp.append(citation_date)\n","            row_tmp.append(retweet)\n","            row_tmp.append(foll)    \n","            row_tmp.append(ment) \n","            row_tmp.append(medi) \n","            row_tmp.append(acti)  \n","            row_tmp.append(auth)\n","            row_tmp.append(favo)\n","            row_tmp.append(titl)        \n","            data_raw.append(row_tmp)\n","    \n","    pddata_raw = pd.DataFrame(data_raw,columns=['time','retweets','followers','mentioned','media', 'active','author','favourites_count','title'])\n","    pddata_raw = pddata_raw.sort_values(by = 'time')\n","    pddata_raw = pddata_raw.reset_index(drop=True)\n","    pddata_raw['tweets'] = 1                   \n","\n","    hour_accu = []\n","    hour_day = []\n","    for index, row in pddata_raw.iterrows():  \n","        p = datetime.datetime.fromtimestamp(row[\"time\"], pst_tz)  \n","        hour_accu.append(((p.month-1)*31+p.day-14)*24+p.hour)\n","        hour_day.append(p.hour)    \n","    pddata_raw[\"time\"] = hour_accu\n","    pddata_raw[\"hour of day\"] = hour_day\n","    \n","    df = pd.DataFrame([],columns=['hour index','tweets','retweets','followers sum','followers max','mentioned','media','active','author','favourites_count','title'])\n","    df['hour index'] = range(pddata_raw.iloc[len(pddata_raw.index)-1,0]+1)\n","    df['tweets'] = pddata_raw.groupby(\"time\")['tweets'].sum()\n","    df['retweets'] = pddata_raw.groupby(\"time\")['retweets'].sum()\n","    df['followers sum'] = pddata_raw.groupby(\"time\")['followers'].sum()\n","    df['followers max'] = pddata_raw.groupby(\"time\")[\"followers\"].max()\n","    df['mentioned'] = pddata_raw.groupby(\"time\")['mentioned'].sum()\n","    df['media'] = pddata_raw.groupby(\"time\")['media'].sum()\n","    df['active'] = pddata_raw.groupby(\"time\")['active'].mean()  \n","    df['author'] = pddata_raw.groupby(\"time\")['author'].nunique() # count number of not-repeating authors    \n","    df['favourites_count'] = pddata_raw.groupby(\"time\")['favourites_count'].sum()\n","    df['title'] = pddata_raw.groupby(\"time\")['title'].mean()\n","    df = df.drop([0]).fillna(0).reset_index(drop=True)\n","    df_y = df.iloc[1:,1].reset_index(drop=True)\n","    df = df[:len(df_y)]\n","    \n","    return df.iloc[:,1:],df_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qy4465dKiBSR","colab_type":"code","colab":{}},"source":["df, df_y = parse_dataset_ten_features(txt[0])\n","for i in range(1,6):\n","    df_temp,df_temp_y=parse_dataset_ten_features(txt[i])\n","    df=df.append(df_temp,ignore_index=True)\n","    df_y=df_y.append(df_temp_y,ignore_index=True)\n","    print(df_temp.shape,df.shape)\n","kf = KFold(n_splits=5,random_state=42,shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mg7jAjFciBPZ","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((8,1))\n","avg_RMSE_test=np.zeros((8,1))\n","max_depth=[10, 20, 40, 60, 80, 100, 200, None]\n","for i in range (0,8):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    depth=max_depth[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        RF = RandomForestRegressor(oob_score=True,n_estimators=200,max_depth=depth,min_samples_leaf=1,min_samples_split=2,max_features='auto',random_state=42)\n","        RF.fit(X_train,y_train)\n","        pred_train = RF.predict(X_train)\n","        pred_test = RF.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max depth: \",depth)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLO6gVFCiKLh","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((2,1))\n","avg_RMSE_test=np.zeros((2,1))\n","max_features=['auto', 'sqrt']\n","for i in range (0,2):\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    feature=max_features[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        RF = RandomForestRegressor(oob_score=True,n_estimators=200,max_depth=20,min_samples_leaf=1,min_samples_split=2,max_features=feature,random_state=42)\n","        RF.fit(X_train,y_train)\n","        pred_train = RF.predict(X_train)\n","        pred_test = RF.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max features: \",feature)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHeULcMbiKH7","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((4,1))\n","avg_RMSE_test=np.zeros((4,1))\n","min_samples_leaf=[1,2,3,4]\n","for i in range (0,4):\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    leaf=min_samples_leaf[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        RF = RandomForestRegressor(oob_score=True,n_estimators=200,max_depth=20,min_samples_leaf=leaf,min_samples_split=2,max_features='sqrt',random_state=42)\n","        RF.fit(X_train,y_train)\n","        pred_train = RF.predict(X_train)\n","        pred_test = RF.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples leaf: \",leaf)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIbXErf-iKEy","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((3,1))\n","avg_RMSE_test=np.zeros((3,1))\n","min_samples_split=[2, 5, 10]\n","for i in range (0,3):\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    split=min_samples_split[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        RF = RandomForestRegressor(oob_score=True,n_estimators=200,max_depth=20,min_samples_leaf=1,min_samples_split=split,max_features='sqrt',random_state=42)\n","        RF.fit(X_train,y_train)\n","        pred_train = RF.predict(X_train)\n","        pred_test = RF.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples split \",split)\n","    print(\"RMSE_train \",avg_RMSE_train[i])\n","    print(\"RMSE_test \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MLqt0VuiKA3","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((10,1))\n","avg_RMSE_test=np.zeros((10,1))\n","n_estimators=[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n","for i in range (0,10):\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    estimator=n_estimators[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        RF = RandomForestRegressor(oob_score=True,n_estimators=estimator,max_depth=20,min_samples_leaf=1,min_samples_split=2,max_features='sqrt',random_state=42)\n","        RF.fit(X_train,y_train)\n","        pred_train = RF.predict(X_train)\n","        pred_test = RF.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"n_estimators: \",estimator)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kC9fEBMbiJ98","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((8,1))\n","avg_RMSE_test=np.zeros((8,1))\n","max_depth=[10, 20, 40, 60, 80, 100, 200, None]\n","for i in range (0,8):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    depth=max_depth[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=depth,min_samples_leaf=1,min_samples_split=2, max_features='auto',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max depth: \",depth)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVYAmW0PivuN","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((2,1))\n","avg_RMSE_test=np.zeros((2,1))\n","max_features=['auto', 'sqrt']\n","for i in range (0,2):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    feature=max_features[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train=df.iloc[train_index]\n","        y_train=df_y.iloc[train_index]\n","        X_test=df.iloc[test_index]\n","        y_test=df_y.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=1,min_samples_split=2, max_features=feature,random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max features: \",feature)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VytK5x-civqh","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((4,1))\n","avg_RMSE_test=np.zeros((4,1))\n","min_samples_leaf=[1, 2, 3, 4]\n","for i in range (0,4):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    leaf=min_samples_leaf[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train=df.iloc[train_index]\n","        y_train=df_y.iloc[train_index]\n","        X_test=df.iloc[test_index]\n","        y_test=df_y.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=leaf,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples leaf: \",leaf)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pp-xUwW5ivl8","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((3,1))\n","avg_RMSE_test=np.zeros((3,1))\n","min_samples_split=[2, 5, 10]\n","for i in range (0,3):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    split=min_samples_split[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=3,min_samples_split=split, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples split: \",split)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxbaeHBOiBKe","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((10,1))\n","avg_RMSE_test=np.zeros((10,1))\n","n_estimators=[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n","for i in range (0,10):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    estimator=n_estimators[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=estimator,max_depth=10,min_samples_leaf=3,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"n estimators: \",estimator)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fULGIxVHiBBj","colab_type":"code","colab":{}},"source":["GB = GradientBoostingRegressor(n_estimators=800,max_depth=depth,min_samples_leaf=1,min_samples_split=2, max_features='sqrt',random_state=42)\n","X = df.iloc[:,:].values\n","y = df_y.iloc[:].values\n","GB.fit(X,y)\n","GB.score(X,y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MlaOyuOwh2pb","colab_type":"text"},"source":["# Question 9"]},{"cell_type":"code","metadata":{"id":"4Ycm5dhgh6nt","colab_type":"code","colab":{}},"source":["X_2 = sm.add_constant(df)\n","y = df_y.as_matrix()\n","X_train, X_test, y_train, y_test = train_test_split(X_2, y, test_size=0.5, random_state=42)\n","ols = sm.OLS(y_train, X_train).fit()\n","print(ols.summary())\n","\n","y_predict = ols.predict(X_test)\n","ols_mse = tools.eval_measures.mse(y_test, y_predict)\n","\n","print(\"MSE for aggregated data:\", ols_mse)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xkkves0tdlFA","colab_type":"text"},"source":["# Question 10"]},{"cell_type":"code","metadata":{"id":"f5IGJ6FAd3kc","colab_type":"code","colab":{}},"source":["import json\n","import datetime\n","import pytz\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error, r2_score\n","from statistics import mean\n","import statsmodels.api as sm\n","import datetime,time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LpZ6YVj1d8PQ","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from statistics import mean\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.datasets import make_regression\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.preprocessing import StandardScaler  \n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.neighbors import KNeighborsRegressor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPFE8pmdd8DS","colab_type":"code","colab":{}},"source":["def parse_dataset_ten_features(txt):\n","    # extract raw features\n","    pst_tz = pytz.timezone('America/Los_Angeles')\n","    data_raw = []\n","    with open(txt, 'r', encoding=\"utf-8\") as current_txt:\n","      for line in current_txt:\n","        row_tmp = []\n","        a = json.loads(line)\n","        citation_date = a['citation_date']\n","        retweet = a['metrics']['citations']['total']\n","        foll = a['author']['followers']             \n","        ment = len(a['tweet']['entities']['user_mentions'])        \n","        medi = len(a['tweet']['extended_entities']['media']) if 'extended_entities' in a['tweet'] else 0\n","        hist_tw = a['tweet']['user'][\"statuses_count\"]\n","        hist_yr = a['tweet']['user']['created_at'][-4:]\n","        acti = hist_tw/(2015-float(hist_yr)+1) \n","        auth = a['author']['name']\n","        favo = a['tweet']['user']['favourites_count']\n","        titl = len(a['title'])\n","        \n","        # append to list\n","        row_tmp.append(citation_date)\n","        row_tmp.append(retweet)\n","        row_tmp.append(foll)    \n","        row_tmp.append(ment) \n","        row_tmp.append(medi) \n","        row_tmp.append(acti)  \n","        row_tmp.append(auth)\n","        row_tmp.append(favo)\n","        row_tmp.append(titl)        \n","        data_raw.append(row_tmp)\n","    \n","    # sort according to time\n","    pddata_raw = pd.DataFrame(data_raw,columns=['time','retweets','followers','mentioned','media',\\\n","                                                'active','author','favourites_count','title'])\n","    pddata_raw = pddata_raw.sort_values(by = 'time')\n","    pddata_raw = pddata_raw.reset_index(drop=True)\n","    pddata_raw['tweets'] = 1                   \n","#     print(pddata_raw)\n","\n","    # reset time to hour index\n","    hour_accu = []\n","    hour_day = []\n","    for index, row in pddata_raw.iterrows():  \n","        p = datetime.datetime.fromtimestamp(row[\"time\"], pst_tz)  \n","        hour_accu.append(((p.month-1)*31+p.day-14)*24+p.hour)\n","        hour_day.append(p.hour)    \n","    pddata_raw[\"time\"] = hour_accu\n","    pddata_raw[\"hour of day\"] = hour_day\n","    \n","    # create a new dataframe with desired form\n","    df = pd.DataFrame([],columns=['hour index','tweets','retweets','followers sum','followers max','mentioned','media','active','author','favourites_count','title'])\n","    df['hour index'] = range(pddata_raw.iloc[len(pddata_raw.index)-1,0]+1)\n","    df['tweets'] = pddata_raw.groupby(\"time\")['tweets'].sum()\n","    df['retweets'] = pddata_raw.groupby(\"time\")['retweets'].sum()\n","    df['followers sum'] = pddata_raw.groupby(\"time\")['followers'].sum()\n","    df['followers max'] = pddata_raw.groupby(\"time\")[\"followers\"].max()\n","    df['mentioned'] = pddata_raw.groupby(\"time\")['mentioned'].sum()\n","    df['media'] = pddata_raw.groupby(\"time\")['media'].sum()\n","    df['active'] = pddata_raw.groupby(\"time\")['active'].mean()  \n","    df['author'] = pddata_raw.groupby(\"time\")['author'].nunique() # count number of not-repeating authors    \n","    df['favourites_count'] = pddata_raw.groupby(\"time\")['favourites_count'].sum()\n","    df['title'] = pddata_raw.groupby(\"time\")['title'].mean()\n","            \n","    # reset index of df\n","    df = df.drop([0]).fillna(0).reset_index(drop=True)\n","\n","    # assign number of tweets of the next hour to be the target value\n","    df_y = df.iloc[1:,1].reset_index(drop=True)\n","    df = df[:len(df_y)]\n","    \n","    return df.iloc[:,1:],df_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1nBcXbncUw3","colab_type":"code","colab":{}},"source":["df, df_y = parse_dataset_ten_features(txts[0])\n","for txt in txts:\n","    df_temp,df_temp_y=parse_dataset_ten_features(txt)\n","    df=df.append(df_temp,ignore_index=True)\n","    df_y=df_y.append(df_temp_y,ignore_index=True)\n","    print(df_temp.shape,df.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4Zy34ScwOnA","colab_type":"code","colab":{}},"source":["param_grid={\n","'max_depth': [10, 20, 40, 60, 80, 100, 200, None],\n","'max_features': ['auto', 'sqrt'],\n","'min_samples_leaf': [1, 2, 4],\n","'min_samples_split': [2, 5, 10],\n","'n_estimators': [200, 400, 600, 800, 1000,\n","1200, 1400, 1600, 1800, 2000]\n","}\n","kf = KFold(n_splits=5,random_state=42,shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6lUkN2KN1KM","colab_type":"code","colab":{}},"source":["(df,df_y),(df_2,df_y_2),(df_3,df_y_3) = parse_dataset_2(txts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7CM28RdtN2Ot","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((8,1))\n","avg_RMSE_test=np.zeros((8,1))\n","max_depth=[10, 20, 40, 60, 80, 100, 200, None]\n","for i in range (0,8):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    depth=max_depth[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=depth,min_samples_leaf=1,min_samples_split=2, max_features='auto',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max depth: \",depth)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmRapDBcTWrc","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((2,1))\n","avg_RMSE_test=np.zeros((2,1))\n","max_features=['auto', 'sqrt']\n","for i in range (0,2):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    feature=max_features[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train=df.iloc[train_index]\n","        y_train=df_y.iloc[train_index]\n","        X_test=df.iloc[test_index]\n","        y_test=df_y.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=1,min_samples_split=2, max_features=feature,random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max features: \",feature)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLhRvWyQN2Lx","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((4,1))\n","avg_RMSE_test=np.zeros((4,1))\n","min_samples_leaf=[1, 2, 3, 4]\n","for i in range (0,4):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    leaf=min_samples_leaf[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train=df.iloc[train_index]\n","        y_train=df_y.iloc[train_index]\n","        X_test=df.iloc[test_index]\n","        y_test=df_y.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=leaf,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples leaf: \",leaf)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGWdQKESN2IW","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((3,1))\n","avg_RMSE_test=np.zeros((3,1))\n","min_samples_split=[2, 5, 10]\n","for i in range (0,3):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    split=min_samples_split[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=3,min_samples_split=split, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples split: \",split)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUrBapnJN19u","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((10,1))\n","avg_RMSE_test=np.zeros((10,1))\n","n_estimators=[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n","for i in range (0,10):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    estimator=n_estimators[i]\n","    for train_index, test_index in kf.split(df):\n","        X_train= df.iloc[train_index]\n","        y_train= df_y.iloc[train_index]\n","        X_test= df.iloc[test_index]\n","        y_test= df_y.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=estimator,max_depth=10,min_samples_leaf=3,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"n estimators: \",estimator)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY_aEfGqTpGy","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((8,1))\n","avg_RMSE_test=np.zeros((8,1))\n","max_depth=[10, 20, 40, 60, 80, 100, 200, None]\n","for i in range (0,8):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    depth=max_depth[i]\n","    for train_index, test_index in kf.split(df_2):\n","        X_train= df_2.iloc[train_index]\n","        y_train= df_y_2.iloc[train_index]\n","        X_test= df_2.iloc[test_index]\n","        y_test= df_y_2.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=depth,min_samples_leaf=1,min_samples_split=2, max_features='auto',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max depth: \",depth)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgB-m0pKTo-3","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((2,1))\n","avg_RMSE_test=np.zeros((2,1))\n","max_features=['auto', 'sqrt']\n","for i in range (0,2):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    feature=max_features[i]\n","    for train_index, test_index in kf.split(df_2):\n","        X_train=df_2.iloc[train_index]\n","        y_train=df_y_2.iloc[train_index]\n","        X_test=df_2.iloc[test_index]\n","        y_test=df_y_2.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=100,min_samples_leaf=1,min_samples_split=2, max_features=feature,random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max features: \",feature)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiBVGv4Zaf6l","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((4,1))\n","avg_RMSE_test=np.zeros((4,1))\n","min_samples_leaf=[1, 2, 3, 4]\n","for i in range (0,4):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    leaf=min_samples_leaf[i]\n","    for train_index, test_index in kf.split(df_2):\n","        X_train=df_2.iloc[train_index]\n","        y_train=df_y_2.iloc[train_index]\n","        X_test=df_2.iloc[test_index]\n","        y_test=df_y_2.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=leaf,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples leaf: \",leaf)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlDpw8cQTowF","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((3,1))\n","avg_RMSE_test=np.zeros((3,1))\n","min_samples_split=[2, 5, 10]\n","for i in range (0,3):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    split=min_samples_split[i]\n","    for train_index, test_index in kf.split(df_2):\n","        X_train= df_2.iloc[train_index]\n","        y_train= df_y_2.iloc[train_index]\n","        X_test= df_2.iloc[test_index]\n","        y_test= df_y_2.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=4,min_samples_split=split, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples split: \",split)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a4P_OJbUROq","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((10,1))\n","avg_RMSE_test=np.zeros((10,1))\n","n_estimators=[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n","for i in range (0,10):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    estimator=n_estimators[i]\n","    for train_index, test_index in kf.split(df_2):\n","        X_train= df_2.iloc[train_index]\n","        y_train= df_y_2.iloc[train_index]\n","        X_test= df_2.iloc[test_index]\n","        y_test= df_y_2.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=estimator,max_depth=10,min_samples_leaf=4,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"n estimators: \",estimator)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-MdStJzURLx","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((8,1))\n","avg_RMSE_test=np.zeros((8,1))\n","max_depth=[10, 20, 40, 60, 80, 100, 200, None]\n","for i in range (0,8):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    depth=max_depth[i]\n","    for train_index, test_index in kf.split(df_3):\n","        X_train= df_3.iloc[train_index]\n","        y_train= df_y_3.iloc[train_index]\n","        X_test= df_3.iloc[test_index]\n","        y_test= df_y_3.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=depth,min_samples_leaf=1,min_samples_split=2, max_features='auto',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max depth: \",depth)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cli_YYyURIn","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((2,1))\n","avg_RMSE_test=np.zeros((2,1))\n","max_features=['auto', 'sqrt']\n","for i in range (0,2):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    feature=max_features[i]\n","    for train_index, test_index in kf.split(df_3):\n","        X_train=df_3.iloc[train_index]\n","        y_train=df_y_3.iloc[train_index]\n","        X_test=df_3.iloc[test_index]\n","        y_test=df_y_3.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=1,min_samples_split=2, max_features=feature,random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"max features: \",feature)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AaBNgMg4btA3","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((4,1))\n","avg_RMSE_test=np.zeros((4,1))\n","min_samples_leaf=[1, 2, 3, 4]\n","for i in range (0,4):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    leaf=min_samples_leaf[i]\n","    for train_index, test_index in kf.split(df_3):\n","        X_train=df_3.iloc[train_index]\n","        y_train=df_y_3.iloc[train_index]\n","        X_test=df_3.iloc[test_index]\n","        y_test=df_y_3.iloc[test_index]\n","        GB=GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=leaf,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train=GB.predict(X_train)\n","        pred_test=GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples leaf: \",leaf)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQ-wvCKXUREI","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((3,1))\n","avg_RMSE_test=np.zeros((3,1))\n","min_samples_split=[2, 5, 10]\n","for i in range (0,3):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    split=min_samples_split[i]\n","    for train_index, test_index in kf.split(df_3):\n","        X_train= df_3.iloc[train_index]\n","        y_train= df_y_3.iloc[train_index]\n","        X_test= df_3.iloc[test_index]\n","        y_test= df_y_3.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=200,max_depth=10,min_samples_leaf=4,min_samples_split=split, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"min samples split: \",split)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RI4yodcUQ-i","colab_type":"code","colab":{}},"source":["avg_RMSE_train=np.zeros((10,1))\n","avg_RMSE_test=np.zeros((10,1))\n","n_estimators=[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n","for i in range (0,10):\n","    MSE_train=[]\n","    MSE_test=[]\n","    total_train=0\n","    total_test=0\n","    estimator=n_estimators[i]\n","    for train_index, test_index in kf.split(df_3):\n","        X_train= df_3.iloc[train_index]\n","        y_train= df_y_3.iloc[train_index]\n","        X_test= df_3.iloc[test_index]\n","        y_test= df_y_3.iloc[test_index]\n","        GB = GradientBoostingRegressor(n_estimators=estimator,max_depth=10,min_samples_leaf=4,min_samples_split=2, max_features='sqrt',random_state=42)\n","        GB.fit(X_train,y_train)\n","        pred_train = GB.predict(X_train)\n","        pred_test = GB.predict(X_test)\n","        MSE_train.append(mean_squared_error(y_train, pred_train)*len(train_index))\n","        MSE_test.append(mean_squared_error(y_test, pred_test)*len(test_index))\n","        total_train=total_train+len(train_index)\n","        total_test=total_test+len(test_index)\n","\n","    avg_RMSE_test[i]=np.sqrt(sum(MSE_test)/total_test)\n","    avg_RMSE_train[i]=np.sqrt(sum(MSE_train)/total_train)\n","    print(\"n estimators: \",estimator)\n","    print(\"RMSE_train: \",avg_RMSE_train[i])\n","    print(\"RMSE_test: \",avg_RMSE_test[i])\n","    print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TQoxD-aBvTp","colab_type":"text"},"source":["# Question 11\n"]},{"cell_type":"code","metadata":{"id":"n2XsgD-HBuM6","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import json\n","import pytz\n","import datetime\n","import time\n","\n","def transform_to_DF(txt_names):\n","    headers = ['timestamp_raw', 'tweets',\n","               'retweets', 'followers', 'followers_max']\n","    dict_df = {}\n","    for key in headers:\n","        dict_df[key] = []\n","    for txt_name in txt_names:\n","        with open(txt_name, 'r', encoding=\"utf8\") as reader:\n","\n","            for line in reader:\n","                json_object = json.loads(line)\n","                dict_df['timestamp_raw'].append(json_object['citation_date'])\n","                dict_df['tweets'].append(1)\n","                dict_df['retweets'].append(json_object['metrics']['citations']['total'])\n","                dict_df['followers'].append(json_object['author']['followers'])\n","                dict_df['followers_max'].append(json_object['author']['followers'])\n","\n","    df = pd.DataFrame(dict_df)\n","    pst_tz = pytz.timezone('America/Los_Angeles')\n","    utc_tz = pytz.UTC\n","    df['date_pst'] = pd.to_datetime(df['timestamp_raw'], unit='s').apply(\n","        lambda x: x.tz_localize(utc_tz).astimezone(pst_tz))\n","    df['date'] = df['date_pst'].apply(lambda x: x.strftime('%Y%m%d'))\n","    df['hour'] = df['date_pst'].apply(lambda x: x.hour)\n","    df['minute'] = df['date_pst'].apply(lambda x: x.minute)\n","    return df\n","\n","def local_to_utc(strtime, local):\n","    naive = datetime.datetime.strptime(strtime, \"%Y-%m-%d %H:%M:%S\")\n","    local_dt = local.localize(naive, is_dst=None)\n","    utc_dt = local_dt.astimezone(pytz.utc)\n","    timestamp = time.mktime(utc_dt.timetuple())\n","    return timestamp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"keOmnJEEKvFO","colab_type":"code","colab":{}},"source":["df = transform_to_DF(txts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UNS7x7yB9pJ","colab_type":"code","colab":{}},"source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","from tempfile import mkdtemp\n","from shutil import rmtree\n","from sklearn.externals.joblib import Memory\n","\n","\n","processed_df = df.groupby(pd.Grouper(key='date_pst', freq='H')).agg(\n","    {'tweets': np.sum, 'retweets': np.sum, 'followers': np.sum, 'followers_max': np.max, 'hour': np.max})\n","\n","X = processed_df.values\n","y = X[1:, 0]\n","truncated_X = X[:-1, :]\n","\n","depths = [2, 3, 5]\n","per_layer_neurons = [20, 30, 50]\n","N_folder = 10\n","hidden_layer_sizes = []\n","for d in depths:\n","    for n in per_layer_neurons:\n","        hidden_layer_sizes.append([n] * d)\n","\n","cachedir = mkdtemp()\n","memory = Memory(cachedir=cachedir, verbose=10)\n","MSE_tuple = []\n","\n","for network_size in hidden_layer_sizes:\n","    pipeline = Pipeline([\n","        ('Regressor', MLPRegressor(hidden_layer_sizes=network_size, max_iter=1000))\n","    ],\n","        memory=memory\n","    )\n","    pipeline.fit(truncated_X, y)\n","    MSE_tuple.append(mean_squared_error(y, pipeline.predict(truncated_X)))\n","    rmtree(cachedir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MyGo54mXLDUu","colab_type":"text"},"source":["# Question 12"]},{"cell_type":"code","metadata":{"id":"Ib278eZVLAuG","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler\n","\n","best_arch_index = MSE_tuple.index(max(MSE_tuple))\n","NN_pipeline = Pipeline([\n","    ('Scaler', StandardScaler()),\n","    ('Regressor', MLPRegressor(hidden_layer_sizes=hidden_layer_sizes[best_arch_index], max_iter=10000))\n","])\n","NN_pipeline.fit(truncated_X, y)\n","after_standardization_error = mean_squared_error(y, NN_pipeline.predict(truncated_X))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HZZZsWE53JWj","colab_type":"text"},"source":["# Question 13"]},{"cell_type":"code","metadata":{"id":"QNAi2oRg3Ib-","colab_type":"code","colab":{}},"source":["start_time_string = '2015-02-01 08:00:00'\n","end_time_string = '2015-02-01 20:00:00'\n","\n","local = pytz.timezone(\"America/Los_Angeles\")\n","start_timestamp = local_to_utc(start_time_string, local)\n","end_timestamp = local_to_utc(end_time_string, local)\n","\n","df_before = df[df.timestamp_raw < start_timestamp]\n","df_after = df[df.timestamp_raw > end_timestamp]\n","df_between = df[(df.timestamp_raw >= start_timestamp) & (df.timestamp_raw <= end_timestamp)]\n","\n","processed_before = df_before.groupby(pd.Grouper(key='date_pst', freq='H')).agg(\n","    {'tweets': np.sum, 'retweets': np.sum, 'followers': np.sum, 'followers_max': np.max, 'hour': np.max})\n","\n","processed_between = df_between.groupby(pd.Grouper(key='date_pst', freq='5Min')).agg(\n","    {'tweets': np.sum, 'retweets': np.sum, 'followers': np.sum, 'followers_max': np.max, 'hour': np.max})\n","\n","processed_after = df_after.groupby(pd.Grouper(key='date_pst', freq='H')).agg(\n","    {'tweets': np.sum, 'retweets': np.sum, 'followers': np.sum, 'followers_max': np.max, 'hour': np.max})\n","\n","X_before = processed_before.values\n","X_between = processed_between.values\n","X_after = processed_after.values\n","y_before = X_before[1:, 0]\n","y_between = X_between[1:, 0]\n","y_after = X_after[1:, 0]\n","\n","X_before_truncated = X_before[:-1, :]\n","X_between_truncated = X_between[:-1, :]\n","X_after_truncated = X_after[:-1, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B21uB3ym3dgU","colab_type":"code","colab":{}},"source":["pipeline2 = Pipeline([\n","    ('Scaler', StandardScaler()),\n","    ('Regressor', MLPRegressor(max_iter=10000))\n","],\n","    memory=memory\n",")\n","param_grid = [\n","    {\n","        'Regressor__hidden_layer_sizes': hidden_layer_sizes\n","    }\n","]\n","\n","grid = GridSearchCV(pipeline2, cv=N_folder, n_jobs=1, param_grid=param_grid, scoring='r2')\n","\n","grid.fit(X_before_truncated, y_before)\n","rmtree(cachedir)\n","result = pd.DataFrame(grid.cv_results_)\n","result.to_excel('Before_Superbowl_result.xls')\n","\n","grid.fit(X_between_truncated, y_between)\n","rmtree(cachedir)\n","result = pd.DataFrame(grid.cv_results_)\n","result.to_excel('Between_Superbowl_result.xls')\n","\n","grid.fit(X_after_truncated, y_after)\n","rmtree(cachedir)\n","result = pd.DataFrame(grid.cv_results_)\n","result.to_excel('After_Superbowl_result.xls')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGNY7hrK7xWj","colab_type":"code","colab":{}},"source":["from google.colab import files\n","\n","files.download('Before_Superbowl_result.xls')\n","files.download('Between_Superbowl_result.xls')\n","files.download('After_Superbowl_result.xls')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3XuaVSODFvMH","colab_type":"text"},"source":["# Question 14"]},{"cell_type":"code","metadata":{"id":"My_RlmmdFqbT","colab_type":"code","colab":{}},"source":["import json\n","import datetime, time\n","import pytz\n","import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestRegressor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMFJHLNhF6HL","colab_type":"code","colab":{}},"source":["def format_data(file):\n","    time_stamp = []\n","    date_time = []\n","    date = []\n","    year = []\n","    month = []\n","    day = []\n","    hour = []\n","    minute = []\n","    retweet_count = []\n","    followers_by_user = []\n","    favorites = []\n","    retweeted = []\n","    mentions = []\n","    rankings = []\n","    impressions = []\n","    url_count = []\n","    file = open(file, \"r\")\n","    for line in file:\n","        data = json.loads(line)\n","        time_stamp.append( data['citation_date'])\n","        \n","        datetime_obj = datetime.datetime.fromtimestamp(data['citation_date'], pst_tz)\n","        date_time.append(datetime_obj)\n","        date.append(datetime_obj.strftime('%Y-%m-%d'))\n","        year.append( datetime_obj.year)\n","        month.append( datetime_obj.month)\n","        day.append( datetime_obj.day)\n","        hour.append( datetime_obj.hour)\n","        minute.append( datetime_obj.minute)\n","        favorites.append(data[\"tweet\"][\"favorite_count\"])\n","        rankings.append(data[\"metrics\"][\"ranking_score\"])\n","        mentions.append(len(data[\"tweet\"][\"entities\"][\"user_mentions\"]))\n","        impressions.append(data[\"metrics\"][\"impressions\"])\n","        retweet_count.append(data['metrics']['citations']['total']) \n","        followers_by_user.append(data['author']['followers'])\n","        url_count.append(len(data[\"tweet\"][\"entities\"][\"urls\"]))\n","        author_name = data['author']['nick']\n","        original_author_name = data['original_author']['nick']\n","        if original_author_name != author_name:\n","            retweeted.append( True )\n","        else:\n","            retweeted.append( False )\n","            \n","    file.close()\n","    \n","    dic = {'time_stamp':time_stamp, 'date_time':date_time,'date':date, 'year':year, 'month':month, \n","           'day' : day, 'hour':hour, 'minute' : minute, \n","           'retweet_count':retweet_count , \"impressions\":impressions, \n","           \"favorites\":favorites, 'followers_by_user':followers_by_user,\n","           'retweeted':retweeted, \"mentions\":mentions, \"rankings\":rankings, \"urls\":url_count}\n","    \n","    df = pd.DataFrame(dic, columns=['time_stamp','date_time','date', 'year', 'month', 'day', \n","                                    'hour', 'minute', 'retweet_count',\"impressions\", \"favorites\", \n","                                    'followers_by_user','retweeted', \"mentions\", \"rankings\", \"urls\"])\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8I3OfMAGPlS","colab_type":"code","colab":{}},"source":["def time_df(df):\n","    date = []\n","    time_of_day = []\n","    minute = []\n","    five_min_tweet_number = []\n","    five_min_retweet_number = []\n","    five_min_sum_of_followers = []\n","    five_min_max_follower = []\n","    five_min_impressions = []\n","    five_min_favorites = []\n","    five_min_mentions = []\n","    five_min_urls = []\n","    five_min_ranking_sum = []\n","    sb_date = '2015-02-01' \n","    sb_start_hr = 8\n","    sb_end_hr = 20\n","    \n","    date_df = df[df.date== sb_date]\n","\n","    for i in range(sb_start_hr,sb_end_hr): \n","        time_frame_df = date_df[date_df.hour == i]\n","\n","        for j in range(0,60,5):\n","            time_frame_df = date_df[(date_df.hour == i) & (j <= date_df.minute) & (date_df.minute<j+5)]\n","            \n","            date.append(sb_date)\n","            time_of_day.append(i)\n","            minute.append(j)\n","\n","            five_min_tweet_number.append(len(time_frame_df.index))\n","            five_min_retweet_number.append(sum(time_frame_df.retweet_count))\n","            five_min_sum_of_followers.append(sum(time_frame_df.followers_by_user))\n","            five_min_max_follower.append(0 if np.isnan(time_frame_df.followers_by_user.max()) else time_frame_df.followers_by_user.max())\n","            five_min_impressions.append(sum(time_frame_df.impressions))\n","            five_min_favorites.append(sum(time_frame_df.favorites))\n","            five_min_mentions.append(sum(time_frame_df.mentions))\n","            five_min_urls.append(sum(time_frame_df.urls))\n","            five_min_ranking_sum.append(sum(time_frame_df.rankings))\n","\n","    target_value = five_min_tweet_number[1:]\n","    target_value.append(five_min_tweet_number[0])\n","    \n","    dic = {'date':date, 'time_of_day': time_of_day, 'minute':minute, 'five_min_tweet_number':five_min_tweet_number, \n","          'five_min_retweet_number':five_min_retweet_number, 'five_min_sum_of_followers':five_min_sum_of_followers,\n","          'five_min_max_follower': five_min_max_follower, \"five_min_impressions\":five_min_impressions,\n","          \"five_min_favorites\":five_min_favorites, \"five_min_mentions\":five_min_mentions,\n","          \"five_min_urls\":five_min_urls, \"five_min_ranking_sum\":five_min_ranking_sum,\n","          \"target_value\":target_value}\n","    \n","    df = pd.DataFrame(dic, columns=['date','time_of_day', 'minute','five_min_tweet_number', \n","          'five_min_retweet_number', 'five_min_sum_of_followers',\n","          'five_min_max_follower', \"five_min_impressions\", \"five_min_favorites\",\n","                                    \"five_min_mentions\", \"five_min_urls\", \"five_min_ranking_sum\", \"target_value\"])\n","\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yibttmACGjRW","colab_type":"code","colab":{}},"source":["def conversion_to_df(hourly_tweet_number, hourly_retweet_number, hourly_sum_of_followers, hourly_max_follower, hourly_impressions, hourly_favorites, hourly_mentions, \n","                         hourly_urls, hourly_ranking_sum, time_of_day, date):\n","    target_value = hourly_tweet_number[1:]\n","    target_value.append(0)\n","    dic = {'date':date, 'time_of_day':time_of_day, 'hourly_tweet_number':hourly_tweet_number,\n","           'hourly_retweet_number':hourly_retweet_number,\n","           'hourly_sum_of_followers':hourly_sum_of_followers,\n","           'hourly_max_follower':hourly_max_follower,\n","           \"hourly_impressions\":hourly_impressions,\n","           \"hourly_favorites\":hourly_favorites,\n","           \"hourly_mentions\":hourly_mentions,\n","           \"hourly_urls\":hourly_urls,\n","           \"hourly_ranking_sum\":hourly_ranking_sum,\n","           'target_value':target_value}\n","    \n","    df = pd.DataFrame(dic, columns=['date','time_of_day', 'hourly_tweet_number', 'hourly_retweet_number', \n","                                    'hourly_sum_of_followers', 'hourly_max_follower', \"hourly_impressions\",\n","                                    \"hourly_favorites\", \"hourly_mentions\", \"hourly_urls\", \"hourly_ranking_sum\",\n","                                    'target_value'])\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AMsQJ-fGt-G","colab_type":"code","colab":{}},"source":["def hourly_df(df):\n","    date = []\n","    time_of_day = []\n","    hourly_tweet_number = []\n","    hourly_retweet_number = []\n","    hourly_sum_of_followers = []\n","    hourly_max_follower = []\n","    hourly_impressions = []\n","    hourly_favorites = []\n","    hourly_mentions = []\n","    hourly_urls = []\n","    hourly_ranking_sum = []\n","    start = datetime.datetime.strptime('2015-01-14', \"%Y-%m-%d\")\n","    end = datetime.datetime.strptime('2015-02-07', \"%Y-%m-%d\")    \n","\n","    all_dates = [(start + datetime.timedelta(days=x)).strftime('%Y-%m-%d') for x in range(0, (end-start).days+1)]\n","\n","    \n","    for current_date in all_dates:\n","        date_df = df[df.date== current_date]\n","    \n","        for i in range (0, 24): \n","            current_hour_df = date_df[date_df.hour == i]\n","\n","            date.append(current_date)\n","            time_of_day.append(i)\n","            \n","            hourly_tweet_number.append(len(current_hour_df.index))\n","            hourly_retweet_number.append(sum(current_hour_df.retweet_count))\n","            hourly_sum_of_followers.append(sum(current_hour_df.followers_by_user))\n","            hourly_max_follower.append(0 if np.isnan(current_hour_df.followers_by_user.max()) else current_hour_df.followers_by_user.max())\n","            hourly_impressions.append(sum(current_hour_df.impressions))\n","            hourly_favorites.append(sum(current_hour_df.favorites))\n","            hourly_mentions.append(sum(current_hour_df.mentions))\n","            hourly_urls.append(sum(current_hour_df.urls))\n","            hourly_ranking_sum.append(sum(current_hour_df.rankings))\n","    return convert_to_df(hourly_tweet_number, hourly_retweet_number, hourly_sum_of_followers, \n","                         hourly_max_follower, hourly_impressions, hourly_favorites, hourly_mentions, \n","                         hourly_urls, hourly_ranking_sum, time_of_day, date)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCtDdI6MHQLW","colab_type":"code","colab":{}},"source":["def get_time_period_dfs(file):\n","    raw_df = get_data(file)\n","    hourly_df = hourly_calculations_df(raw_df)\n","    before_game_df = hourly_df[(hourly_df.date < '2015-02-01') | ((hourly_df.date == '2015-02-01') & (hourly_df.time_of_day < 5))]\n","    after_game_df = hourly_df[(hourly_df.date > '2015-02-01') | ((hourly_df.date == '2015-02-01') & (hourly_df.time_of_day >8))]\n","    \n","    game_time_df = game_time_calculations_df(raw_df)\n","    \n","    return before_game_df,game_time_df,after_game_df,hourly_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"487UDhSBHYp4","colab_type":"code","colab":{}},"source":["before_game_df_list = []\n","after_game_df_list = []\n","game_time_df_list = []\n","hourly_df_list = []\n","for txt in txts:\n","    print(txt)\n","    before_game_df, game_time_df, after_game_df, hourly_df = get_time_period_dfs(txt)\n","    before_game_df_list.append(before_game_df)\n","    game_time_df_list.append(game_time_df)\n","    after_game_df_list.append(after_game_df)\n","    hourly_df_list.append(hourly_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_AzXLJOHyCb","colab_type":"code","colab":{}},"source":["for sample in samples:\n","    print(\"On \" + sample)\n","    file = \"ECE219_tweet_test/\" + sample\n","    rf = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse', max_depth=200,\n","    max_features='auto', min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2,\n","    min_weight_fraction_leaf=0.0, n_estimators=1200, verbose=0)\n","    before_test_df, test_df, after_test_df, hour_df = get_time_period_dfs(file)\n","    if sample[-5] == \"2\":\n","        hour_df = test_df\n","        hour_df = hour_df[hour_df.five_min_tweet_number > 0]\n","        sample_df = agg_game_df\n","    else:\n","        hour_df = hour_df[hour_df.hourly_tweet_number > 0]\n","        sample_df = agg_hourly_df\n","    training_start_date = \"2015-01-14\"\n","    training_end_date = \"2015-02-07\"\n","    end_date = hour_df.iloc[-1].date\n","    end_time = hour_df.iloc[-1].time_of_day\n","    if end_date > training_end_date:\n","        sample_df = sample_df.iloc[-5:]\n","    elif end_date < training_start_date:\n","        df = sample_df.iloc[0:5]\n","    else:\n","        if sample[-5] != \"2\":\n","            end_index = sample_df[(sample_df.date == end_date) & (sample_df.time_of_day==end_time)].index[0]\n","        else:\n","            end_minute = hour_df.iloc[-1].minute\n","            end_index = sample_df[(sample_df.date == end_date) & (sample_df.minute==end_minute) & (sample_df.time_of_day==end_time)].index[0]\n","        start_index = end_index-5\n","        sample_df = sample_df.iloc[start_index:end_index]\n","    x, y = get_x_y(sample_df)\n","    hour_df = hour_df.iloc[0:-1]\n","    x_test, y_test = get_x_y(hour_df)\n","    rf.fit(x, y)\n","    print(\"Prediction: \" + \"\\n\" +str(rf.predict(x_test)[-1]))\n","    print(\"Actual: \" + \"\\n\" + str(y_test.iloc[-1]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3NRdMzUkIIHX","colab_type":"text"},"source":["# Question 15"]},{"cell_type":"code","metadata":{"id":"IqeffSdvIKK_","colab_type":"code","colab":{}},"source":["import json\n","tweets_sb = []\n","with open('/content/tweets_#gopatriots.txt' , 'r') as f:\n","    for i, l in enumerate(f):\n","        tweet = json.loads(l)\n","        tweets_sb.append(tweet)\n","\n","import re\n","import numpy as np\n","import itertools\n","from sklearn.feature_extraction import text\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.model_selection import train_test_split\n","from nltk import word_tokenize\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem import PorterStemmer\n","from sklearn.metrics import confusion_matrix\n","from sklearn import datasets, linear_model\n","import matplotlib.pyplot as plt\n","\n","washington = ['Seattle, Washington', 'Washington', 'WA', 'Seattle, WA', 'Kirkland, Washington']\n","massachusetts = ['Massachusetts', 'MA','Mass','Boston，Massachusetts','Boston, MA']\n","class MyTokenizer(object):\n","    def __init__(self):\n","        self.stemmer = PorterStemmer()\n","        self.token_pattern = re.compile(u'(?u)\\\\b\\\\w\\\\w+\\\\b')\n","        \n","    def __call__(self, doc):\n","        return [self.stemmer.stem(w) for w in self.token_pattern.findall(doc)]\n","\n","vectorizer = CountVectorizer(min_df=3, stop_words=text.ENGLISH_STOP_WORDS, tokenizer=MyTokenizer()) \n","tfidf_transformer = TfidfTransformer()\n","\n","def location(loc):\n","    for wt in washington:\n","        if loc.lower().find(wt.lower()) >= 0:\n","            return \"washington\" # 0\n","    for mt in massachusetts:\n","        if loc.lower().find(mt.lower()) >= 0:\n","            return \"massachusetts\" # 1\n","    return None\n","\n","X, Y = [], []\n","for tweet in tweets_sb:\n","    location = find_location(tweet['tweet']['user']['location'])\n","    if location is None: continue # does not belong to either state\n","    X.append(tweet['tweet']['text'])\n","    Y.append(0 if location == \"washington\" else 1)\n","\n","X = vectorizer.fit_transform(X)\n","X = tfidf_transformer.fit_transform(X)\n","Y = np.array(Y)\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n","logistic = linear_model.LogisticRegression()\n","logistic.fit(X_train, Y_train)\n","Y_pred = logistic.predict(X_test)\n","Y_pred_prob = logistic.predict_proba(X_test)\n","\n","class_names = ['WA', 'MA']\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Reds):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Unnomalized Confusion matrix')\n","\n","    print(cm)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Actual')\n","    plt.xlabel('Predicted')\n","\n","cnf_matrix = confusion_matrix(Y_test, Y_pred)\n","np.set_printoptions(precision=2)\n","\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names,\n","                      title='Unnormalized Confusion matrix')\n","\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n","                      title='Normalized confusion matrix')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-O8ab6xJcK9","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","fpr, tpr, thresholds = roc_curve(Y_test, Y_pred_prob[:,0], pos_label=0)\n","roc_auc = auc(fpr, tpr)\n","\n","plt.figure()\n","lw = 2\n","plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p-cE7rthJdhR","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score\n","print('Accuracy = %.3f, Precision = %.3f, Recall = %.3f' % (accuracy_score(Y_test, Y_pred), precision_score(Y_test, Y_pred), recall_score(Y_test, Y_pred)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zfSzzpvcJSUA","colab_type":"text"},"source":["# Question 16"]},{"cell_type":"code","metadata":{"id":"apJCMCB_JRm-","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction import text\n","def extract(hashtag, folder):\n","    titles = []\n","    times = []\n","    location = []\n","    for key in hashtag_dict:\n","        ipt = open(folder + hashtag_dict[key])   \n","        for line in ipt:\n","            data = json.loads(line)\n","            titles.append(data['title'])\n","            times.append(data['citation_date'])\n","            loc = data['tweet']['user']['location']\n","            if loc == 'Washington' or ', Washington' in loc or loc == 'WA' or ', WA' in loc:\n","                location.append(-1)\n","            elif loc == 'Massachusetts' or ', Massachusetts' in loc or loc == 'MA' or ', MA' in loc:\n","                location.append(1)\n","            else:\n","                location.append(0)\n","    return titles, times, location\n","titles, times, locations = extract_tweets(hashtag_dict, './tweet_data/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJUgizxpJ5qv","colab_type":"code","colab":{}},"source":["def tfidf(matrix):\n","    count_vect = text.CountVectorizer(min_df=3, stop_words='english')\n","    X_train_counts = count_vect.fit_transform(matrix)\n","    tfidf_transformer = text.TfidfTransformer()\n","    tfidf = tfidf_transformer.fit_transform(X_train_counts)\n","    return tfidf, count_vect"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrpkqBFtKILP","colab_type":"code","colab":{}},"source":["from sklearn.decomposition import NMF\n","nmf_model = NMF(n_components=2, init='random', random_state=0)\n","for i in range(len(splitted_titles)):\n","    item = splitted_titles[i]\n","    loc = splitted_locations[i]\n","    print(time_slices[i])\n","    tfidf, count_vect = matrix2tfidf(item)\n","    \n","    #check tweets\n","    a11 = 0\n","    a12 = 0\n","    a21 = 0\n","    a22 = 0\n","    line_num = 0   \n","    tweet_dis = nmf_model.fit_transform(tfidf)\n","    for line in tweet_dis:\n","        if loc[line_num] == 1:\n","            left += 1\n","        elif loc[line_num] == -1:\n","            right += 1\n","        if line[0] > line[1]: \n","            if loc[line_num] == 1:\n","                a11 += 1\n","            elif loc[line_num] == -1:\n","                a12 += 1\n","        else:\n","            if loc[line_num] == 1:\n","                a21 += 1\n","            elif loc[line_num] == -1:\n","                a22 += 1\n","        line_num += 1\n","        print(a11, a12)\n","        print(a21, a22)\n","    \n","        word_dis = nmf_model.components_\n","        word_sorted = np.argsort(-word_dis, axis = 1)[:,:10]\n","        words = count_vect.get_feature_names()\n","        for line in word_sorted:\n","          for k in line:\n","              print(words[k],' ' ,end = '')\n","          print('\\n')"],"execution_count":0,"outputs":[]}]}